{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-analytic functional decoding\n",
    "## Discrete functional decoding\n",
    "\n",
    "In this notebook, we applied meta-analytic functional decoding using the NiMARE (https://nimare.readthedocs.io/en/stable/about.html). Specifically, we used the discrete decoding approach, which estimates the statistical association between brain regions and cognitive terms based on large-scale meta-analytic databases (e.g., Neurosynth).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel import Nifti1Image\n",
    "\n",
    "from nilearn import datasets, image, plotting\n",
    "from nilearn.plotting import plot_roi\n",
    "from nilearn.image import load_img\n",
    "from nilearn.masking import _unmask_3d\n",
    "from nilearn.maskers import nifti_spheres_masker\n",
    "\n",
    "import nimare\n",
    "from nimare.stats import pearson\n",
    "from nimare.dataset import Dataset\n",
    "from nimare.decode import discrete, continuous\n",
    "from nimare.utils import get_resource_path\n",
    "from nimare.extract import fetch_neurosynth\n",
    "from nimare.io import convert_neurosynth_to_dataset\n",
    "\n",
    "# print the current working directory\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.extract.utils:Dataset found in ../Data/neurosynth\n",
      "\n",
      "INFO:nimare.extract.extract:Searching for any feature files matching the following criteria: [('data-neurosynth', 'version-7')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data-neurosynth_version-7_coordinates.tsv.gz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_metadata.tsv.gz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA100_keys.tsv\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA100_metadata.json\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA100_source-abstract_type-weight_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA100_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA200_keys.tsv\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA200_metadata.json\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA200_source-abstract_type-weight_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA200_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA400_keys.tsv\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA400_metadata.json\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA400_source-abstract_type-weight_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA400_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_keys.tsv\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_metadata.json\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_source-abstract_type-weight_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-terms_source-abstract_type-tfidf_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-terms_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:nimare.utils:Not applying transforms to coordinates in unrecognized space 'UNKNOWN'\n"
     ]
    }
   ],
   "source": [
    "# get neurosynth data\n",
    "databases = nimare.extract.fetch_neurosynth(data_dir='../Data')[0]\n",
    "\n",
    "# convert to NiMARE dataset (Note: This can take a while!)\n",
    "ds = nimare.io.convert_neurosynth_to_dataset(\n",
    "    coordinates_file=databases['coordinates'],\n",
    "    metadata_file=databases['metadata'],\n",
    "    annotations_files=databases['features']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>contrast_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>10022492-1</td>\n",
       "      <td>10022492</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>10022492-1</td>\n",
       "      <td>10022492</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>10022492-1</td>\n",
       "      <td>10022492</td>\n",
       "      <td>1</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>10022492-1</td>\n",
       "      <td>10022492</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>10022492-1</td>\n",
       "      <td>10022492</td>\n",
       "      <td>1</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>9990082-1</td>\n",
       "      <td>9990082</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>9990082-1</td>\n",
       "      <td>9990082</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>9990082-1</td>\n",
       "      <td>9990082</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>9990082-1</td>\n",
       "      <td>9990082</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>9990082-1</td>\n",
       "      <td>9990082</td>\n",
       "      <td>1</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>mni152_2mm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507891 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  study_id contrast_id     x     y     z       space\n",
       "1483  10022492-1  10022492           1  36.0 -58.0  52.0  mni152_2mm\n",
       "1499  10022492-1  10022492           1  48.0  24.0  20.0  mni152_2mm\n",
       "1498  10022492-1  10022492           1 -42.0  26.0  20.0  mni152_2mm\n",
       "1497  10022492-1  10022492           1 -36.0  30.0  16.0  mni152_2mm\n",
       "1496  10022492-1  10022492           1 -30.0  32.0   0.0  mni152_2mm\n",
       "...          ...       ...         ...   ...   ...   ...         ...\n",
       "1479   9990082-1   9990082           1  42.0 -54.0 -21.0  mni152_2mm\n",
       "1480   9990082-1   9990082           1 -36.0 -87.0  -6.0  mni152_2mm\n",
       "1481   9990082-1   9990082           1  30.0 -81.0 -15.0  mni152_2mm\n",
       "1467   9990082-1   9990082           1 -18.0 -60.0  54.0  mni152_2mm\n",
       "1482   9990082-1   9990082           1 -21.0 -78.0  27.0  mni152_2mm\n",
       "\n",
       "[507891 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨cognitive atlasçš„æœ¯è¯­è¿›è¡Œè§£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Cognitive Atlas terms...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print(\"Fetching Cognitive Atlas terms...\")\n",
    "base_url = \"https://www.cognitiveatlas.org/api/v-alpha\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1771 cognitive terms from Cognitive Atlas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "concepts = requests.get(f\"{base_url}/concept?format=json\").json()\n",
    "tasks = requests.get(f\"{base_url}/task?format=json\").json()\n",
    "\n",
    "cognitive_terms = [c['name'].lower() for c in concepts] + [t['name'].lower() for t in tasks]\n",
    "\n",
    "print(f\"Fetched {len(cognitive_terms)} cognitive terms from Cognitive Atlas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering annotations to retain only cognitive terms...\n",
      "Remaining features after filtering: 133\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering annotations to retain only cognitive terms...\")\n",
    "terms_to_keep = ['id'] + [\n",
    "    col for col in ds.annotations.columns\n",
    "    if col.split('__')[-1].lower() in cognitive_terms\n",
    "]\n",
    "\n",
    "ds.annotations = ds.annotations[terms_to_keep]\n",
    "print(f\"Remaining features after filtering: {len(ds.annotations.columns) - 1}\")\n",
    "\n",
    "# ğŸ§© å…³é”®ä¿®å¤éƒ¨åˆ†\n",
    "if 'study_id' not in ds.annotations.columns:\n",
    "    ds.annotations['study_id'] = ds.annotations['id']\n",
    "if 'contrast_id' not in ds.annotations.columns:\n",
    "    ds.annotations['contrast_id'] = ds.annotations['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running continuous decoding for /Users/ss/Documents/Self_Psych_Meta/Output/1_ALE/control_all_z_thresh.nii.gz...\n"
     ]
    }
   ],
   "source": [
    "from nimare.decode import continuous\n",
    "\n",
    "zmap_path = \"/Users/ss/Documents/Self_Psych_Meta/Output/1_ALE/control_all_z_thresh.nii.gz\"  # <-- ä¿®æ”¹ä¸ºä½ çš„ z-map è·¯å¾„\n",
    "\n",
    "print(f\"Running continuous decoding for {zmap_path}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decoder parameters\n",
    "frequency_threshold = 0.001\n",
    "u = 0.05\n",
    "correction = \"fdr_bh\"\n",
    "\n",
    "decoder = continuous.CorrelationDecoder(\n",
    "    frequency_threshold=frequency_threshold,\n",
    "    target_image=zmap_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No map with name '/Users/ss/Documents/Self_Psych_Meta/Output/1_ALE/control_all_z_thresh.nii.gz' found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m decoded_df \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mtransform()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nimare/decode/base.py:108\u001b[0m, in \u001b[0;36mDecoder.fit\u001b[0;34m(self, dataset, drop_invalid)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_inputs(dataset, drop_invalid\u001b[38;5;241m=\u001b[39mdrop_invalid)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_input(dataset)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nimare/decode/continuous.py:199\u001b[0m, in \u001b[0;36mCorrelationDecoder._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate feature-specific meta-analytic maps for dataset.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    MetaResult with meta-analytic maps and masker added.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_)\n\u001b[1;32m    197\u001b[0m maps \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    198\u001b[0m     r: v\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r, v \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    200\u001b[0m         Parallel(return_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_cores)(\n\u001b[1;32m    201\u001b[0m             delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_fit)(feature, dataset) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_\n\u001b[1;32m    202\u001b[0m         ),\n\u001b[1;32m    203\u001b[0m         total\u001b[38;5;241m=\u001b[39mn_features,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m }\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_ \u001b[38;5;241m=\u001b[39m MetaResult(\u001b[38;5;28mself\u001b[39m, mask\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmasker, maps\u001b[38;5;241m=\u001b[39mmaps)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nimare/decode/continuous.py:229\u001b[0m, in \u001b[0;36mCorrelationDecoder._run_fit\u001b[0;34m(self, feature, dataset)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     meta_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_estimator\u001b[38;5;241m.\u001b[39mfit(feature_dset)\n\u001b[0;32m--> 229\u001b[0m feature_data \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature, feature_data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nimare/results.py:132\u001b[0m, in \u001b[0;36mMetaResult.get_map\u001b[0;34m(self, name, return_type)\u001b[0m\n\u001b[1;32m    130\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaps\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo map with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# pending resolution of https://github.com/nilearn/nilearn/issues/2724\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No map with name '/Users/ss/Documents/Self_Psych_Meta/Output/1_ALE/control_all_z_thresh.nii.gz' found."
     ]
    }
   ],
   "source": [
    "decoder.fit(ds)\n",
    "decoded_df = decoder.transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder.fit(ds)\n",
    "decoded_df = decoder.transform()\n",
    "\n",
    "# Save results\n",
    "out_csv = \"zmap_decoding_results.csv\"\n",
    "decoded_df.to_csv(out_csv, index=False)\n",
    "print(f\"Decoding results saved to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.cognitiveatlas.org', port=443): Max retries exceeded with url: /api/v-alpha/concept?format=json (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;31mSSLError\u001b[0m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.cognitiveatlas.org', port=443): Max retries exceeded with url: /api/v-alpha/concept?format=json (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m disorders_endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/disorder?format=json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Fetch concepts and tasks data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m concepts_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcepts_endpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tasks_response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(tasks_endpoint)\n\u001b[1;32m     13\u001b[0m disorders_response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(disorders_endpoint)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/requests/adapters.py:698\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='www.cognitiveatlas.org', port=443): Max retries exceeded with url: /api/v-alpha/concept?format=json (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cognitive Atlas API base URL\n",
    "base_url = \"https://www.cognitiveatlas.org/api/v-alpha\"\n",
    "\n",
    "# Endpoints for concepts, tasks, and disorders\n",
    "concepts_endpoint = f\"{base_url}/concept?format=json\"\n",
    "tasks_endpoint = f\"{base_url}/task?format=json\"\n",
    "disorders_endpoint = f\"{base_url}/disorder?format=json\"\n",
    "\n",
    "\n",
    "# Fetch concepts and tasks data\n",
    "concepts_response = requests.get(concepts_endpoint)\n",
    "tasks_response = requests.get(tasks_endpoint)\n",
    "disorders_response = requests.get(disorders_endpoint)\n",
    "\n",
    "# Extract names from the response data\n",
    "concepts = concepts_response.json()\n",
    "tasks = tasks_response.json()\n",
    "disorders = disorders_response.json()\n",
    "\n",
    "# Get the names of concepts and tasks\n",
    "concept_names = [concept['name'] for concept in concepts]\n",
    "task_names = [task['name'] for task in tasks]\n",
    "disorder_names = [disorder['name'] for disorder in disorders]\n",
    "\n",
    "cognitive_atlas_terms = concept_names + task_names + disorder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_keep = ['id'] + [\n",
    "    term for term in ds.annotations.columns \n",
    "    if term.split('__')[-1].replace('_', ' ') in cognitive_atlas_terms\n",
    "]\n",
    "\n",
    "ds.annotations = ds.annotations[terms_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.annotations.columns[:10])\n",
    "print(cognitive_atlas_terms[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decoder parameters\n",
    "frequency_threshold = 0.001\n",
    "u = 0.05\n",
    "correction = \"fdr_bh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare.decode.continuous import CorrelationDecoder\n",
    "from nimare.meta.cbma import mkda\n",
    "from nilearn.image import load_img\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_img_path = \"/Users/ss/Documents/Self_Psych_Meta/Output/1_ALE/control_all_z_thresh.nii\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = CorrelationDecoder(ale_img_path,\n",
    "    frequency_threshold=frequency_threshold,\n",
    "    meta_estimator=mkda.MKDAChi2,\n",
    "    target_image='z_desc-association'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder.fit(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoded_df = decoder.transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('/Users/ss/Documents/Self_Psych_Meta/Output/6_Decoding', exist_ok=True)\n",
    "decoded_df.to_csv('/Users/ss/Documents/Self_Psych_Meta/Output/6_Decoding/control_all_decode.csv', index=True)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder.fit(ds)\n",
    "decoded_df = decoder.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.to_csv('/Users/ss/Documents/Self_Psych_Meta/Output/6_Decoding/L_Angular.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "\n",
    "# å®šä¹‰è¾“å…¥æ–‡ä»¶åˆ—è¡¨\n",
    "csv_files = [\n",
    "    '../results/extract_decoding/extract_Angular_decode.csv',\n",
    "    '../results/extract_decoding/extract_Cingulate_decode.csv',\n",
    "    '../results/extract_decoding/extract_FPole_decode.csv',\n",
    "    '../results/extract_decoding/extract_L_FOC_decode.csv',\n",
    "    '../results/extract_decoding/extract_R_FOC_decode.csv',\n",
    "    '../results/extract_decoding/extract_PCG_decode.csv'\n",
    "]\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºç›®å½•\n",
    "output_dir = '../results/wordcloud'\n",
    "os.makedirs(output_dir, exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# å®šä¹‰è¾“å…¥æ–‡ä»¶åˆ—è¡¨\n",
    "csv_files = [\n",
    "    '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud/control_clean.csv',\n",
    "    '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud/control_minus_patient_clean.csv',\n",
    "    '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud/patient_clean.csv',\n",
    "    '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud/patient_minus_control_clean.csv',\n",
    "    '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud/sz_clean.csv'\n",
    "]\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºç›®å½•\n",
    "output_dir = '/Users/ss/Documents/Self_Psych_Meta/Output/wordcloud'\n",
    "os.makedirs(output_dir, exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º\n",
    "\n",
    "\n",
    "# æ‰¹é‡å¤„ç†æ¯ä¸ª CSV æ–‡ä»¶\n",
    "for file_path in csv_files:\n",
    "    # è¯»å– CSV æ•°æ®\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # æ„å»ºè¯é¢‘å­—å…¸ï¼Œä½¿ç”¨ 'feature' ä½œä¸ºå•è¯ï¼Œ'r' ä½œä¸ºè¯é¢‘\n",
    "    word_frequencies = data.set_index('feature')['r'].to_dict()\n",
    "\n",
    "    # åˆ›å»ºè¯äº‘\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        colormap=\"Reds\",\n",
    "        background_color='white',\n",
    "        max_words=150,\n",
    "        max_font_size=150,\n",
    "        scale=3,\n",
    "        relative_scaling=0.5,\n",
    "        prefer_horizontal=1.0\n",
    "    ).generate_from_frequencies(word_frequencies)\n",
    "\n",
    "    # ç»˜åˆ¶å¹¶æ˜¾ç¤ºè¯äº‘å›¾\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # å…³é—­åæ ‡è½´\n",
    "\n",
    "    # è·å–'r'å€¼çš„èŒƒå›´ï¼Œç”¨äºcolor bar\n",
    "    r_values = list(word_frequencies.values())\n",
    "    vmin, vmax = min(r_values), max(r_values)\n",
    "\n",
    "    # åˆ›å»ºä¸€ä¸ªæ ‡é‡æ˜ å°„å¯¹è±¡ï¼Œç”¨äºcolor bar\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=norm)\n",
    "    sm.set_array([])  \n",
    "\n",
    "    # æ·»åŠ color bar\n",
    "    cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('', rotation=270, labelpad=15)  # è®¾ç½®color barçš„æ ‡ç­¾\n",
    "\n",
    "    # æ˜¾ç¤ºå›¾åƒ\n",
    "    plt.show()\n",
    "\n",
    "    # ä¿å­˜è¯äº‘å›¾ä¸ºæ–‡ä»¶\n",
    "    file_name = os.path.basename(file_path).replace('extract_', '').replace('_decode.csv', '')  # æå–æ–‡ä»¶åçš„ä¸€éƒ¨åˆ†\n",
    "    output_path = os.path.join(output_dir, f'{file_name}_wordcloud.png')\n",
    "    wordcloud.to_file(output_path)\n",
    "\n",
    "    print(f\"è¯äº‘å›¾å·²ä¿å­˜åˆ° {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡å¤„ç†æ¯ä¸ª CSV æ–‡ä»¶\n",
    "# \"viridis\" ç»¿è‰²\n",
    "for file_path in csv_files:\n",
    "    # è¯»å– CSV æ•°æ®\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # æ„å»ºè¯é¢‘å­—å…¸ï¼Œä½¿ç”¨ 'cognitive_feature' ä½œä¸ºå•è¯ï¼Œ'r' ä½œä¸ºè¯é¢‘\n",
    "    word_frequencies = data.set_index('cognitive_feature')['r'].to_dict()\n",
    "\n",
    "    # åˆ›å»ºè¯äº‘\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        colormap=\"YlOrRd\",\n",
    "        background_color='white',\n",
    "        prefer_horizontal=1.0\n",
    "    ).generate_from_frequencies(word_frequencies)\n",
    "\n",
    "    # ç»˜åˆ¶å¹¶æ˜¾ç¤ºè¯äº‘å›¾\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # å…³é—­åæ ‡è½´\n",
    "    plt.show()\n",
    "\n",
    "    # ä¿å­˜è¯äº‘å›¾ä¸ºæ–‡ä»¶\n",
    "    file_name = os.path.basename(file_path).replace('extract_', '').replace('_decode.csv', '')  # æå–æ–‡ä»¶åçš„ä¸€éƒ¨åˆ†\n",
    "    output_path = os.path.join(output_dir, f'{file_name}_wordcloud.png')\n",
    "    wordcloud.to_file(output_path)\n",
    "\n",
    "    print(f\"è¯äº‘å›¾å·²ä¿å­˜åˆ° {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
