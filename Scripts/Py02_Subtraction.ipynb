{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Subtraction analysis\n",
    "This code is largely based on the implementation provided by Enge et al. (2021), available at https://osf.io/34ry2/. We are deeply grateful for their dedication to open research.\n",
    "\n",
    "> Enge, A., Abdel Rahman, R., & Skeide, M. A. (2021). A meta-analysis of fMRI studies of semantic cognition in children. NeuroImage, 241, 118436. https://doi.org/10.1016/j.neuroimage.2021.118436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ss/miniconda3/envs/meta_fmri/lib/python3.8/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n",
      "/Users/ss/miniconda3/envs/meta_fmri/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from os import makedirs, path\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from nibabel import save\n",
    "from nilearn import glm, image, plotting, reporting\n",
    "from nimare import io, meta\n",
    "import os\n",
    "\n",
    "# Print current working directory \n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before doing the actual subtraction analyses, let's define a helper function for statistical thresholding. Since no FWE correction method has been defined for subtraction analyses (yet), we use an uncorrected voxel-level threshold (usually $p<.001$) combined with a cluster-level extent threshold (in mm<sup>3</sup>). Note that we assume the voxel size to be 2×2×2 mm<sup>3</sup> (the default in NiMARE).\n",
    "# Define helper function for dual threshold based on voxel-p and cluster size (in mm3)\n",
    "def dual_thresholding(\n",
    "    img_z, voxel_thresh, cluster_size_mm3, two_sided=True, fname_out=None\n",
    "):\n",
    "\n",
    "    # If img_z is a file path, we first need to load the actual image\n",
    "    img_z = image.load_img(img=img_z)\n",
    "\n",
    "    # Check if the image is empty\n",
    "    if np.all(img_z.get_fdata() == 0):\n",
    "        print(\"THE IMAGE IS EMPTY! RETURNING THE ORIGINAL IMAGE.\")\n",
    "        return img_z\n",
    "\n",
    "    # Convert desired cluster size to the corresponding number of voxels\n",
    "    k = cluster_size_mm3 // 8\n",
    "\n",
    "    # Actual thresholding\n",
    "    img_z_thresh, thresh_z = glm.threshold_stats_img(\n",
    "        stat_img=img_z,\n",
    "        alpha=voxel_thresh,\n",
    "        height_control=\"fpr\",\n",
    "        cluster_threshold=k,\n",
    "        two_sided=two_sided,\n",
    "    )\n",
    "\n",
    "    # Print the thresholds that we've used\n",
    "    print(\n",
    "        \"THRESHOLDING IMAGE AT Z > \"\n",
    "        + str(thresh_z)\n",
    "        + \" (P = \"\n",
    "        + str(voxel_thresh)\n",
    "        + \") AND K > \"\n",
    "        + str(k)\n",
    "        + \" (\"\n",
    "        + str(cluster_size_mm3)\n",
    "        + \" mm3)\"\n",
    "    )\n",
    "\n",
    "    # If requested, save the thresholded map\n",
    "    if fname_out:\n",
    "        save(img_z_thresh, filename=fname_out)\n",
    "\n",
    "    return img_z_thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can go on to perform the actual subtraction analyses. \n",
    "# Define function for performing a single ALE subtraction analysis\n",
    "def run_subtraction(\n",
    "    text_file1,\n",
    "    text_file2,\n",
    "    voxel_thresh,\n",
    "    cluster_size_mm3,\n",
    "    random_seed,\n",
    "    n_iters,\n",
    "    output_dir,\n",
    "):\n",
    "\n",
    "    # Let's show the user what we are doing\n",
    "    print(\n",
    "        'SUBTRACTION ANALYSIS FOR \"'\n",
    "        + text_file1\n",
    "        + '\" VS. \"'\n",
    "        + text_file2\n",
    "        + '\" WITH '\n",
    "        + str(n_iters)\n",
    "        + \" PERMUTATIONS\"\n",
    "    )\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Read Sleuth files\n",
    "    dset1 = io.convert_sleuth_to_dataset(text_file=text_file1)\n",
    "    dset2 = io.convert_sleuth_to_dataset(text_file=text_file2)\n",
    "\n",
    "    # Actually perform subtraction analysis\n",
    "    sub = meta.cbma.ALESubtraction(n_iters=n_iters, low_memory=False)\n",
    "    sres = sub.fit(dset1, dset2)\n",
    "\n",
    "    # Save the unthresholded z map\n",
    "    img_z = sres.get_map(\"z_desc-group1MinusGroup2\")\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    name1 = path.basename(text_file1).replace(\".txt\", \"\")\n",
    "    name2 = path.basename(text_file2).replace(\".txt\", \"\")\n",
    "    prefix = output_dir + \"/\" + name1 + \"_minus_\" + name2\n",
    "    save(img_z, filename=prefix + \"_z.nii.gz\")\n",
    "\n",
    "    # Create and save the thresholded z map\n",
    "    dual_thresholding(\n",
    "        img_z=img_z,\n",
    "        voxel_thresh=voxel_thresh,\n",
    "        cluster_size_mm3=cluster_size_mm3,\n",
    "        two_sided=True,\n",
    "        fname_out=prefix + \"_z_thresh.nii.gz\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to first text file: control group foci\n",
    "text_file1 =\"../Data/AnalysisData/Coordinates/Control_all.txt\"\n",
    "\n",
    "# Define path to first text file: patient group foci\n",
    "text_file2 =\"../Data/AnalysisData/Coordinates/patient.txt\"\n",
    "\n",
    "# Define output directory\n",
    "output_dir=\"../Output/2_Subtraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the subtraction analysis\n",
    "run_subtraction(\n",
    "    text_file1=text_file1,\n",
    "    text_file2=text_file2,\n",
    "    voxel_thresh=0.001,\n",
    "    cluster_size_mm3=200,\n",
    "    random_seed=2024,\n",
    "    n_iters=10000,\n",
    "    output_dir=output_dir\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
