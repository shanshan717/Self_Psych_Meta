{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Activation likelihood estimation\n",
    "This code is largely based on the implementation provided by Enge et al. (2021), available at https://osf.io/34ry2/. We are deeply grateful for their dedication to open research.\n",
    "\n",
    "> Enge, A., Abdel Rahman, R., & Skeide, M. A. (2021). A meta-analysis of fMRI studies of semantic cognition in children. NeuroImage, 241, 118436. https://doi.org/10.1016/j.neuroimage.2021.118436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from os import makedirs, path\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from nibabel import save\n",
    "from nilearn import glm, image, plotting, reporting\n",
    "from nimare import io, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALE analysis: Conjunction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before doing the actual subtraction analyses, let's define a helper function for statistical thresholding. Since no FWE correction method has been defined for subtraction analyses (yet), we use an uncorrected voxel-level threshold (usually $p<.001$) combined with a cluster-level extent threshold (in mm<sup>3</sup>). Note that we assume the voxel size to be 2×2×2 mm<sup>3</sup> (the default in NiMARE).\n",
    "\n",
    "# Define helper function for dual threshold based on voxel-p and cluster size (in mm3)\n",
    "def dual_thresholding(\n",
    "    img_z, voxel_thresh, cluster_size_mm3, two_sided=True, fname_out=None\n",
    "):\n",
    "\n",
    "    # If img_z is a file path, we first need to load the actual image\n",
    "    img_z = image.load_img(img=img_z)\n",
    "\n",
    "    # Check if the image is empty\n",
    "    if np.all(img_z.get_fdata() == 0):\n",
    "        print(\"THE IMAGE IS EMPTY! RETURNING THE ORIGINAL IMAGE.\")\n",
    "        return img_z\n",
    "\n",
    "    # Convert desired cluster size to the corresponding number of voxels\n",
    "    k = cluster_size_mm3 // 8\n",
    "\n",
    "    # Actual thresholding\n",
    "    img_z_thresh, thresh_z = glm.threshold_stats_img(\n",
    "        stat_img=img_z,\n",
    "        alpha=voxel_thresh,\n",
    "        height_control=\"fpr\",\n",
    "        cluster_threshold=k,\n",
    "        two_sided=two_sided,\n",
    "    )\n",
    "\n",
    "    # Print the thresholds that we've used\n",
    "    print(\n",
    "        \"THRESHOLDING IMAGE AT Z > \"\n",
    "        + str(thresh_z)\n",
    "        + \" (P = \"\n",
    "        + str(voxel_thresh)\n",
    "        + \") AND K > \"\n",
    "        + str(k)\n",
    "        + \" (\"\n",
    "        + str(cluster_size_mm3)\n",
    "        + \" mm3)\"\n",
    "    )\n",
    "\n",
    "    # If requested, save the thresholded map\n",
    "    if fname_out:\n",
    "        save(img_z_thresh, filename=fname_out)\n",
    "\n",
    "    return img_z_thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can go on to perform the actual subtraction analyses. We again define a helper function for this so we can apply this to multiple Sleuth files with a single call (and also reuse it in later notebooks). We simply read two Sleuth files into NiMARE and let its `meta.cbma.ALESubtraction()` function do the rest (as briefly described above). It outputs an unthresholded *z* score map which we then threshold using our helper function.\n",
    "# Define function for performing a single ALE subtraction analysis\n",
    "def run_subtraction(\n",
    "    text_file1,\n",
    "    text_file2,\n",
    "    voxel_thresh,\n",
    "    cluster_size_mm3,\n",
    "    random_seed,\n",
    "    n_iters,\n",
    "    output_dir,\n",
    "):\n",
    "\n",
    "    # Let's show the user what we are doing\n",
    "    print(\n",
    "        'SUBTRACTION ANALYSIS FOR \"'\n",
    "        + text_file1\n",
    "        + '\" VS. \"'\n",
    "        + text_file2\n",
    "        + '\" WITH '\n",
    "        + str(n_iters)\n",
    "        + \" PERMUTATIONS\"\n",
    "    )\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Read Sleuth files\n",
    "    dset1 = io.convert_sleuth_to_dataset(text_file=text_file1)\n",
    "    dset2 = io.convert_sleuth_to_dataset(text_file=text_file2)\n",
    "\n",
    "    # Actually perform subtraction analysis\n",
    "    sub = meta.cbma.ALESubtraction(n_iters=n_iters, low_memory=False)\n",
    "    sres = sub.fit(dset1, dset2)\n",
    "\n",
    "    # Save the unthresholded z map\n",
    "    img_z = sres.get_map(\"z_desc-group1MinusGroup2\")\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    name1 = path.basename(text_file1).replace(\".txt\", \"\")\n",
    "    name2 = path.basename(text_file2).replace(\".txt\", \"\")\n",
    "    prefix = output_dir + \"/\" + name1 + \"_minus_\" + name2\n",
    "    save(img_z, filename=prefix + \"_z.nii.gz\")\n",
    "\n",
    "    # Create and save the thresholded z map\n",
    "    dual_thresholding(\n",
    "        img_z=img_z,\n",
    "        voxel_thresh=voxel_thresh,\n",
    "        cluster_size_mm3=cluster_size_mm3,\n",
    "        two_sided=True,\n",
    "        fname_out=prefix + \"_z_thresh.nii.gz\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALE analysis: Contrast analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function for dual threshold based on voxel-p and cluster size (in mm3)\n",
    "def dual_thresholding(\n",
    "    img_z, voxel_thresh, cluster_size_mm3, two_sided=True, fname_out=None\n",
    "):\n",
    "\n",
    "    # If img_z is a file path, we first need to load the actual image\n",
    "    img_z = image.load_img(img=img_z)\n",
    "\n",
    "    # Check if the image is empty\n",
    "    if np.all(img_z.get_fdata() == 0):\n",
    "        print(\"THE IMAGE IS EMPTY! RETURNING THE ORIGINAL IMAGE.\")\n",
    "        return img_z\n",
    "\n",
    "    # Convert desired cluster size to the corresponding number of voxels\n",
    "    k = cluster_size_mm3 // 8\n",
    "\n",
    "    # Actual thresholding\n",
    "    img_z_thresh, thresh_z = glm.threshold_stats_img(\n",
    "        stat_img=img_z,\n",
    "        alpha=voxel_thresh,\n",
    "        height_control=\"fpr\",\n",
    "        cluster_threshold=k,\n",
    "        two_sided=two_sided,\n",
    "    )\n",
    "\n",
    "    # Print the thresholds that we've used\n",
    "    print(\n",
    "        \"THRESHOLDING IMAGE AT Z > \"\n",
    "        + str(thresh_z)\n",
    "        + \" (P = \"\n",
    "        + str(voxel_thresh)\n",
    "        + \") AND K > \"\n",
    "        + str(k)\n",
    "        + \" (\"\n",
    "        + str(cluster_size_mm3)\n",
    "        + \" mm3)\"\n",
    "    )\n",
    "\n",
    "    # If requested, save the thresholded map\n",
    "    if fname_out:\n",
    "        save(img_z_thresh, filename=fname_out)\n",
    "\n",
    "    return img_z_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for performing a single ALE subtraction analysis\n",
    "def run_subtraction(\n",
    "    text_file1,\n",
    "    text_file2,\n",
    "    voxel_thresh,\n",
    "    cluster_size_mm3,\n",
    "    random_seed,\n",
    "    n_iters,\n",
    "    output_dir,\n",
    "):\n",
    "\n",
    "    # Let's show the user what we are doing\n",
    "    print(\n",
    "        'SUBTRACTION ANALYSIS FOR \"'\n",
    "        + text_file1\n",
    "        + '\" VS. \"'\n",
    "        + text_file2\n",
    "        + '\" WITH '\n",
    "        + str(n_iters)\n",
    "        + \" PERMUTATIONS\"\n",
    "    )\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Read Sleuth files\n",
    "    dset1 = io.convert_sleuth_to_dataset(text_file=text_file1)\n",
    "    dset2 = io.convert_sleuth_to_dataset(text_file=text_file2)\n",
    "\n",
    "    # Actually perform subtraction analysis\n",
    "    sub = meta.cbma.ALESubtraction(n_iters=n_iters, low_memory=False)\n",
    "    sres = sub.fit(dset1, dset2)\n",
    "\n",
    "    # Save the unthresholded z map\n",
    "    img_z = sres.get_map(\"z_desc-group1MinusGroup2\")\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    name1 = path.basename(text_file1).replace(\".txt\", \"\")\n",
    "    name2 = path.basename(text_file2).replace(\".txt\", \"\")\n",
    "    prefix = output_dir + \"/\" + name1 + \"_minus_\" + name2\n",
    "    save(img_z, filename=prefix + \"_z.nii.gz\")\n",
    "\n",
    "    # Create and save the thresholded z map\n",
    "    dual_thresholding(\n",
    "        img_z=img_z,\n",
    "        voxel_thresh=voxel_thresh,\n",
    "        cluster_size_mm3=cluster_size_mm3,\n",
    "        two_sided=True,\n",
    "        fname_out=prefix + \"_z_thresh.nii.gz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file1 =\"../data/ale_analysis_foci/control.txt\"\n",
    "text_file2 =\"../data/ale_analysis_foci/patient.txt\"\n",
    "\n",
    "output_dir=\"../results/subtraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBTRACTION ANALYSIS FOR \"../data/ale_analysis_foci/control.txt\" VS. \"../data/ale_analysis_foci/patient.txt\" WITH 10 PERMUTATIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:nimare.meta.cbma.base:Unused keyword arguments found: (('low_memory', False),)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5022d813a41189454238bedd912f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccea382b05243f898482fd093c736d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLDING IMAGE AT Z > 3.2905267314918945 (P = 0.001) AND K > 25 (200 mm3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/nilearn/glm/thresholding.py:297: UserWarning: The given float value must not exceed 1.6448536269514729. But, you have given threshold=3.2905267314918945.\n",
      "  stat_img = threshold_img(\n"
     ]
    }
   ],
   "source": [
    "run_subtraction(\n",
    "    text_file1=text_file1,\n",
    "    text_file2=text_file2,\n",
    "    voxel_thresh=0.001,\n",
    "    cluster_size_mm3=200,\n",
    "    random_seed=1234,\n",
    "    n_iters=10,\n",
    "    output_dir=\"../results/subtraction\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute seperate difference maps for children > adults and adults > children\n",
    "img_sub = image.load_img(output_dir + \"children_minus_adults_z_thresh.nii.gz\")\n",
    "img_children_gt_adults = image.math_img(\"np.where(img > 0, img, 0)\", img=img_sub)\n",
    "img_adults_gt_children = image.math_img(\"np.where(img < 0, img * -1, 0)\", img=img_sub)\n",
    "_ = save(img_children_gt_adults, output_dir + \"children_greater_adults_z_thresh.nii.gz\")\n",
    "_ = save(img_adults_gt_children, output_dir + \"adults_greater_children_z_thresh.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finally, we also compute a conjunction map. This map shows all the brain regions that are engaged in semantic cognition in *both* groups (but not those specific to either one of them). For these voxels, we just take the smaller of the two *z* values from both group-specific *z* score maps (Nichols et al., 2005, *NeuroImage*). We then do the same for the ALE maps so we have our conjunction maps with both *z* scores and ALE values.\n",
    "\n",
    "\n",
    "# Compute conjunction z map (= minimum voxel-wise z score across both groups)\n",
    "formula = \"np.where(img1 * img2 > 0, np.minimum(img1, img2), 0)\"\n",
    "img_adults_z = image.load_img(output_dir + \"adults_z_thresh.nii.gz\")\n",
    "img_children_z = image.load_img(\"../results/ale/all_z_thresh.nii.gz\")\n",
    "img_conj_z = image.math_img(formula, img1=img_adults_z, img2=img_children_z)\n",
    "_ = save(img_conj_z, output_dir + \"children_conj_adults_z.nii.gz\")\n",
    "\n",
    "# Compute conjunction ALE map (= minimum voxel-wise ALE value across both groups)\n",
    "img_adults_ale = image.load_img(output_dir + \"adults_stat_thresh.nii.gz\")\n",
    "img_children_ale = image.load_img(\"../results/ale/all_stat_thresh.nii.gz\")\n",
    "img_conj_ale = image.math_img(formula, img1=img_adults_ale, img2=img_children_ale)\n",
    "_ = save(img_conj_ale, output_dir + \"children_conj_adults_ale.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
